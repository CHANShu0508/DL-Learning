{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ab5380",
   "metadata": {},
   "source": [
    "# 线性代数\n",
    "\n",
    "## 降维\n",
    "\n",
    "我们对于矩阵的降维通常称为“求和”。其实就是对于行或列进行求和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a5640a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3953361",
   "metadata": {},
   "source": [
    "上面我们成功把一个一维的 tensor 将为零维哈哈。\n",
    "\n",
    "当然，我们也可以对行或列进行求和，只需要指定轴即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d3cc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.]]),\n",
       " tensor([24., 28., 32., 36.]),\n",
       " tensor([ 6., 22., 38., 54.]),\n",
       " torch.Size([4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(16, dtype=torch.float32).reshape(4, -1)\n",
    "\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A, A_sum_axis0, A_sum_axis1, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c00af0",
   "metadata": {},
   "source": [
    "所以，对于求和：\n",
    "\n",
    "- `axis=0` 就是对每一列求和\n",
    "- `axis=1` 就是对每一行求和\n",
    "\n",
    "这个轴和上一节提到的删除 Pandas 中的行/列代指的有所不同"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f6ee7",
   "metadata": {},
   "source": [
    "## 矩阵的一些量\n",
    "\n",
    "### 均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ffd983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.5000), tensor(7.5000))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel() # 二者等价"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91622b",
   "metadata": {},
   "source": [
    "也可以沿着行或列求平均值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d2130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 7., 8., 9.]), tensor([6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]  # 二者等价。对每一列求均值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ee784",
   "metadata": {},
   "source": [
    "## 非降维求和\n",
    "\n",
    "我们也可以在不降低维度（不改变 `tensor` 尺寸的情况下求和）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61dc812c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[24., 28., 32., 36.]]),\n",
       " tensor([[ 6.],\n",
       "         [22.],\n",
       "         [38.],\n",
       "         [54.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A_0 = A.sum(axis=0, keepdim=True)\n",
    "sum_A_1 = A.sum(axis=1, keepdim=True)\n",
    "sum_A_0, sum_A_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb426a13",
   "metadata": {},
   "source": [
    "对吧，没有改变尺寸。\n",
    "\n",
    "然后，我们还可以求一个 cumulative sum 累计求和。可以从小的矩阵看出端倪这是啥："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d309d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [5, 7, 9]]),\n",
       " tensor([[ 1,  3,  6],\n",
       "         [ 4,  9, 15]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "torch.cumsum(aa, axis=0), torch.cumsum(aa, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfa58a",
   "metadata": {},
   "source": [
    "对列求 `cumsum` 的时候：\n",
    "\n",
    "- 第一行：`1=1`, `2=2`, `3=3`\n",
    "- 第二行：`5=1+4`, `7=2+5`, `9=3+6`\n",
    "\n",
    "对行求得时候：\n",
    "\n",
    "- 第一列：`1=1`, `4=4`\n",
    "- 第二列：`3=1+2`, `9=4+5`\n",
    "- 第三列：`6=1+2+3`, `15=4+5+6`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db326cd3",
   "metadata": {},
   "source": [
    "## 范数\n",
    "\n",
    "简介：[范数](https://zh-v2.d2l.ai/chapter_preliminaries/linear-algebra.html#subsec-lin-algebra-norms)\n",
    "\n",
    "### $L_2$ 范数\n",
    "\n",
    "$L_2$ 范数其实就是常叫的**向量的模**，也就是所有向量的分量的平方和的平方根：\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{x}\\|_2=\\sqrt{\\sum_{i=1}^n x_i^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "390fc2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac1d1e",
   "metadata": {},
   "source": [
    "### $L_1$ 范数\n",
    "\n",
    "$L_1$ 范数是所有元素的绝对值之和：\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{x}\\|_1=\\sum_{i=1}^n \\left| x \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e5c2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce790171",
   "metadata": {},
   "source": [
    "### 一般范数形式 $L_p$\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{x}\\|_p=\\left(\\sum_{i=1}^n\\left|x_i\\right|^p\\right)^{1 / p}\n",
    "$$\n",
    "\n",
    "### 矩阵的 $L_2$ 范数\n",
    "\n",
    "类似于向量的 $L_2$ 范数，矩阵有一个 *Frobenius* 范数：\n",
    "\n",
    "$$\n",
    "\\| \\mathbf{X} \\|_F = \\sqrt{ \\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a3e30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = torch.ones(4, 9)\n",
    "torch.norm(bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3017e",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "算了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
